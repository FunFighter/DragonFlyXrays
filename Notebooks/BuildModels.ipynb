{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<weakproxy at 0x000001D7F21170E8 to Device at 0x000001D7F1FB8278>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import gc\n",
    "import time\n",
    "from itertools import chain\n",
    "from _thread import start_new_thread\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import regularizers, optimizers\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, Flatten, Activation, Dropout, MaxPooling2D, BatchNormalization\n",
    "\n",
    "from numba import cuda\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.backend.tensorflow_backend import clear_session\n",
    "from keras.backend.tensorflow_backend import get_session\n",
    "\n",
    "# @TODO build CI\n",
    "import scipy.stats\n",
    "\n",
    "cuda.select_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @TODO Get this working an import\n",
    "\n",
    "def LabelPicker(label='Cardiomegaly'):\n",
    "    global train_df\n",
    "    global test_df\n",
    "    global df\n",
    "    df = de_df[de_df['Finding Labels'] == label]\n",
    "    \n",
    "    df = pd.concat([df,NoF_df])\n",
    "    \n",
    "    train_df = pd.merge(train_filter,df , on='Image Index', how='inner')\n",
    "    test_df = pd.merge(test_filter,df , on='Image Index', how='inner')\n",
    "    \n",
    "def ResetHard():\n",
    "    #Dump GPU memory after save\n",
    "    print('Starting Dump')\n",
    "    cuda.close()\n",
    "    print('Cuda Closed')\n",
    "    K.clear_session()\n",
    "    print('Session Cleared')\n",
    "    del model\n",
    "    print('del model')\n",
    "    gc.collect()\n",
    "    print('Finishing Dump')\n",
    "    # My god damn hero\n",
    "    # https://github.com/keras-team/keras/issues/9379#issuecomment-477414618\n",
    "    # The reason behind it is: Tensorflow is just allocating memory to the GPU, while CUDA is responsible for managing the GPU memory.\n",
    "    \n",
    "\n",
    "#Attach CSV to Images Folder and defline our traiing validation and test\n",
    "def vaild_gen(batch_fit, Class_Value, TARGET_SIZE):\n",
    "    global valid_generator\n",
    "    valid_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=\"../images/\",\n",
    "        x_col=\"Image Index\",\n",
    "        y_col=label,\n",
    "        subset=\"validation\",\n",
    "        class_mode=Class_Value,\n",
    "        target_size=(TARGET_SIZE,TARGET_SIZE),\n",
    "        batch_size=batch_fit)\n",
    "    \n",
    "def train_gen(batch_fit, Class_Value, TARGET_SIZE):\n",
    "    global train_generator\n",
    "    train_generator=datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=\"../images/\",\n",
    "        x_col=\"Image Index\",\n",
    "        y_col=label,\n",
    "        subset=\"training\",\n",
    "        class_mode=Class_Value,\n",
    "        target_size=(TARGET_SIZE,TARGET_SIZE),\n",
    "        batch_size=batch_fit)\n",
    "    \n",
    "def test_gen(batch_fit, Class_Value, TARGET_SIZE):\n",
    "    global test_generator\n",
    "    test_generator=test_datagen.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        directory=\"../images/\",\n",
    "        x_col=\"Image Index\",\n",
    "        y_col=label,\n",
    "        class_mode=Class_Value,\n",
    "        target_size=(TARGET_SIZE,TARGET_SIZE),\n",
    "        batch_size=batch_fit)\n",
    "    \n",
    "def init_gens(batch_fit, class_value, target):\n",
    "    start_new_thread(vaild_gen,(batch_fit, class_value,target,  ))\n",
    "    start_new_thread(train_gen,(batch_fit, class_value,target, ))\n",
    "    start_new_thread(test_gen,(batch_fit, class_value,target, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "BBox_df = pd.read_csv('../BBox_List_2017.csv',dtype=str)\n",
    "de_df = pd.read_csv('../Data_Entry_2017.csv',dtype=str)\n",
    "train_filter = pd.read_csv('../train_val_list.txt',dtype=str)\n",
    "train_filter.columns=['Image Index']\n",
    "test_filter = pd.read_csv('../test_list.txt',dtype=str)\n",
    "test_filter.columns=['Image Index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Labels (14): ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n"
     ]
    }
   ],
   "source": [
    "bad_ages = de_df[de_df['Patient Age'].astype(int) >= 110].index\n",
    "\n",
    "de_df = de_df.drop(bad_ages)\n",
    "\n",
    "de_df['Finding Labels'] = de_df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\n",
    "\n",
    "all_labels = np.unique(list(chain(*de_df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
    "\n",
    "all_labels = [x for x in all_labels if len(x) > 0]\n",
    "\n",
    "print('All Labels ({}): {}'.format(len(all_labels), all_labels))\n",
    "\n",
    "for c_label in all_labels:\n",
    "    if len(c_label)>1: # leave out empty labels\n",
    "        de_df[c_label] = de_df['Finding Labels'].map(lambda finding: '1' if c_label in finding else '0')\n",
    "\n",
    "de_df = de_df.drop(columns=['Unnamed: 11','Patient Gender','View Position','Patient Age','Patient ID','Follow-up #','OriginalImagePixelSpacing[x','y]','OriginalImage[Width','Height]'])\n",
    "\n",
    "NoF_df = de_df[de_df['Finding Labels'] == '' ].sample(30000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/255 adjust the color\n",
    "datagen = ImageDataGenerator(rescale=1./255 ,validation_split=0.25)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Class Mode\n",
    "Class_Value = 'categorical'\n",
    "\n",
    "# Target_size for resolution 1:1\n",
    "TARGET_SIZE = 230\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# To denote a single label to test on\n",
    "# label = 'Infiltration'\n",
    "# LabelPicker(label)\n",
    "\n",
    "# init_gens(BATCH_SIZE ,Class_Value, TARGET_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x000001D7899DCC88>\n",
      "WARNING:tensorflow:From C:\\Users\\saber\\Anaconda3\\envs\\tfGPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\saber\\Anaconda3\\envs\\tfGPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#define Model\n",
    "model = Sequential()\n",
    "print(model)\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(TARGET_SIZE,TARGET_SIZE,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StartLoop\n",
      "Starting Sleep\n",
      "Found 4935 validated image filenames belonging to 2 classes.\n",
      "Found 6293 validated image filenames belonging to 2 classes.Found 18881 validated image filenames belonging to 2 classes.\n",
      "\n",
      "Finishing Sleep\n",
      "WARNING:tensorflow:From C:\\Users\\saber\\Anaconda3\\envs\\tfGPU\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "590/590 [==============================] - 80s 136ms/step - loss: 0.0402 - acc: 0.9976 - val_loss: 0.0488 - val_acc: 0.9970\n",
      "sleeping part 2\n",
      " Saving to : SavedModels/Hernia.h5\n",
      "StartLoop\n",
      "Starting Sleep\n",
      "Found 7111 validated image filenames belonging to 2 classes.\n",
      "Found 8108 validated image filenames belonging to 2 classes.Found 24327 validated image filenames belonging to 2 classes.\n",
      "\n",
      "Finishing Sleep\n",
      "Epoch 1/1\n",
      "760/760 [==============================] - 98s 129ms/step - loss: 1.7752 - acc: 0.7546 - val_loss: 0.4446 - val_acc: 0.8297\n",
      "sleeping part 2\n",
      " Saving to : SavedModels/Infiltration.h5\n",
      "StartLoop\n",
      "Starting Sleep\n",
      "Found 5334 validated image filenames belonging to 2 classes.\n",
      "Found 6701 validated image filenames belonging to 2 classes.\n",
      "Found 20104 validated image filenames belonging to 2 classes.\n",
      "Finishing Sleep\n",
      "Epoch 1/1\n",
      "628/628 [==============================] - 82s 130ms/step - loss: 0.2653 - acc: 0.9316 - val_loss: 0.2067 - val_acc: 0.9522\n",
      "sleeping part 2\n",
      " Saving to : SavedModels/Mass.h5\n",
      "StartLoop\n",
      "Starting Sleep\n",
      "Found 5348 validated image filenames belonging to 2 classes.\n",
      "Found 6839 validated image filenames belonging to 2 classes.\n",
      "Found 20518 validated image filenames belonging to 2 classes.\n",
      "Finishing Sleep\n",
      "Epoch 1/1\n",
      "641/641 [==============================] - 83s 130ms/step - loss: 0.2994 - acc: 0.9165 - val_loss: 0.2823 - val_acc: 0.9218\n",
      "sleeping part 2\n",
      " Saving to : SavedModels/Nodule.h5\n",
      "StartLoop\n",
      "Starting Sleep\n",
      "Found 5200 validated image filenames belonging to 2 classes.\n",
      "Found 6481 validated image filenames belonging to 2 classes.\n",
      "Found 19445 validated image filenames belonging to 2 classes.\n",
      "Finishing Sleep\n",
      "Epoch 1/1\n",
      "607/607 [==============================] - 79s 130ms/step - loss: 0.1471 - acc: 0.9693 - val_loss: 0.1524 - val_acc: 0.9658\n",
      "sleeping part 2\n",
      " Saving to : SavedModels/Pleural_Thickening.h5\n",
      "StartLoop\n",
      "Starting Sleep\n",
      "Found 4979 validated image filenames belonging to 2 classes.\n",
      "Found 19008 validated image filenames belonging to 2 classes.\n",
      "Found 6335 validated image filenames belonging to 2 classes.\n",
      "Finishing Sleep\n",
      "Epoch 1/1\n",
      "594/594 [==============================] - 77s 130ms/step - loss: 0.0615 - acc: 0.9906 - val_loss: 0.0607 - val_acc: 0.9914\n",
      "sleeping part 2\n",
      " Saving to : SavedModels/Pneumonia.h5\n",
      "StartLoop\n",
      "Starting Sleep\n",
      "Found 5843 validated image filenames belonging to 2 classes.\n",
      "Found 19763 validated image filenames belonging to 2 classes.\n",
      "Found 6587 validated image filenames belonging to 2 classes.\n",
      "Finishing Sleep\n",
      "Epoch 1/1\n",
      "617/617 [==============================] - 81s 131ms/step - loss: 0.1932 - acc: 0.9543 - val_loss: 0.2163 - val_acc: 0.9486\n",
      "sleeping part 2\n",
      " Saving to : SavedModels/Pneumothorax.h5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for label in all_labels:\n",
    "    print('StartLoop')\n",
    "    LabelPicker(label)\n",
    "    \n",
    "    # Init_Gens will \"complete\" before its ready to move on. time.sleep(10) is the crude fix.\n",
    "    init_gens(BATCH_SIZE ,Class_Value, TARGET_SIZE)\n",
    "    \n",
    "    # Will need to adjust delay based on the system\n",
    "    print('Starting Sleep')\n",
    "    time.sleep(7)\n",
    "    print('Finishing Sleep')\n",
    "    \n",
    "    STEP_SIZE_VALID= valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "    STEP_SIZE_TRAIN= train_generator.n//train_generator.batch_size\n",
    "\n",
    "\n",
    "    model.compile(optimizers.rmsprop(lr=0.0001),\n",
    "    loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "\n",
    "    model.fit_generator(generator=train_generator,\n",
    "                        steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                        validation_data=valid_generator,\n",
    "                        validation_steps=STEP_SIZE_VALID,\n",
    "                        workers=16,\n",
    "                        use_multiprocessing=False,\n",
    "                        epochs=1) \n",
    "    \n",
    "    \n",
    "    time.sleep(5)\n",
    "    print('sleeping part 2')\n",
    "    model.save(f'Models/{label}.h5')\n",
    "    print(f' Saving to : SavedModels/{label}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StartLoop\n",
      "Starting Sleep\n",
      "Found 4885 validated image filenames belonging to 2 classes.\n",
      "Found 6359 validated image filenames belonging to 2 classes.\n",
      "Found 19078 validated image filenames belonging to 2 classes.\n",
      "Finishing Sleep\n",
      "WARNING:tensorflow:From C:\\Users\\saber\\Anaconda3\\envs\\tfGPU\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "[0.12194633322513637, 0.9819078947368421]\n",
      "StartLoop\n",
      "Starting Sleep\n",
      "Found 5749 validated image filenames belonging to 2 classes.\n",
      "Found 6611 validated image filenames belonging to 2 classes.Found 19833 validated image filenames belonging to 2 classes.\n",
      "\n",
      "Finishing Sleep\n",
      "[0.621801699631374, 0.8344972067039106]\n",
      "EndLoop\n"
     ]
    }
   ],
   "source": [
    "# Save test results to dict for review and CI\n",
    "test_results_dict = {}\n",
    "test_size_dict = {}\n",
    "\n",
    "\n",
    "for label in all_labels:\n",
    "    print('StartLoop')\n",
    "    \n",
    "    LabelPicker(label)\n",
    "    \n",
    "    # Init_Gens will \"complete\" before its ready to move on. time.sleep(10) is the crude fix.\n",
    "    init_gens(BATCH_SIZE ,Class_Value, TARGET_SIZE)\n",
    "    print('Starting Sleep')\n",
    "    time.sleep(7)\n",
    "    print('Finishing Sleep')\n",
    "\n",
    "    model = load_model(f'Models/{label}.h5')\n",
    "    \n",
    "    STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "\n",
    "\n",
    "    model_test_results = model.evaluate_generator(generator=test_generator,\n",
    "                        steps=STEP_SIZE_TEST,\n",
    "                        workers=16,\n",
    "                        use_multiprocessing=False,\n",
    "                       )\n",
    "    print(model_test_results)\n",
    "    \n",
    "    test_size = len(test_generator.filenames)\n",
    "    \n",
    "    test_results_dict.update({label : model_test_results})\n",
    "    \n",
    "    test_size_dict.update({label : test_size})\n",
    "\n",
    "    \n",
    "print('EndLoop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Dump\n",
      "Cuda Closed\n",
      "Session Cleared\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'model' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-9e51ce5c8d74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mResetHard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-fdf3752979ee>\u001b[0m in \u001b[0;36mResetHard\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Session Cleared'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[1;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'del model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'model' referenced before assignment"
     ]
    }
   ],
   "source": [
    "ResetHard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_size</th>\n",
       "      <th>loss</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pneumonia</th>\n",
       "      <td>4885</td>\n",
       "      <td>0.121946</td>\n",
       "      <td>0.981908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pneumothorax</th>\n",
       "      <td>5749</td>\n",
       "      <td>0.621802</td>\n",
       "      <td>0.834497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sample_size      loss  test_acc\n",
       "Pneumonia            4885  0.121946  0.981908\n",
       "Pneumothorax         5749  0.621802  0.834497"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results = pd.DataFrame(test_results_dict).T\n",
    "Results.columns = ['loss','test_acc']\n",
    "\n",
    "test_val = pd.DataFrame(pd.Series(test_size_dict))\n",
    "test_val.columns = ['sample_size']\n",
    "\n",
    "final_results = pd.concat([test_val, Results],axis=1)\n",
    "\n",
    "final_results.to_csv('res/round3.csv')\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
