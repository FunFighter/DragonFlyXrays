{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "\"\"\"Import from keras_preprocessing not from keras.preprocessing, because Keras may or maynot contain the features discussed here depending upon when you read this article, until the keras_preprocessed library is updated in Keras use the github version.\"\"\"\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.engine import Input, Model\n",
    "from keras import regularizers, optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Labels (14): ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "BBox_df = pd.read_csv('../BBox_List_2017.csv',dtype=str)\n",
    "de_df = pd.read_csv('../Data_Entry_2017.csv',dtype=str)\n",
    "train_filter = pd.read_csv('../train_val_list.txt',dtype=str)\n",
    "train_filter.columns=['Image Index']\n",
    "test_filter = pd.read_csv('../test_list.txt',dtype=str)\n",
    "test_filter.columns=['Image Index']\n",
    "\n",
    "#Clean Data\n",
    "\n",
    "# remove people over 100, Found some people that are labeled \"412\" years old\n",
    "bad_ages = de_df[de_df['Patient Age'].astype(int) >= 100].index\n",
    "de_df = de_df.drop(bad_ages)\n",
    "\n",
    "# Break the | into columns\n",
    "all_labels = np.unique(list(chain(*de_df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
    "all_labels = [x for x in all_labels if len(x) > 0]\n",
    "\n",
    "# Take the Labels and one hot encode them\n",
    "for c_label in all_labels:\n",
    "    if len(c_label)>1: # leave out empty labels\n",
    "        de_df[c_label] = de_df['Finding Labels'].map(lambda finding: 1 if c_label in finding else 0)\n",
    "\n",
    "# remove the unneeded columns from the df\n",
    "de_df = de_df.drop(columns=['Finding Labels','Unnamed: 11','Patient Gender','View Position','Patient Age','Patient ID','Follow-up #','OriginalImagePixelSpacing[x','y]','OriginalImage[Width','Height]'])\n",
    "NoF_df = de_df.sample(20000)\n",
    "\n",
    "all_labels.remove('No Finding')\n",
    "\n",
    "print('All Labels ({}): {}'.format(len(all_labels), all_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>Mass</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_000.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image Index  Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n",
       "0  00000001_000.png            0             1              0      0   \n",
       "1  00000001_001.png            0             1              0      0   \n",
       "2  00000001_002.png            0             1              0      0   \n",
       "3  00000002_000.png            0             0              0      0   \n",
       "4  00000003_000.png            0             0              0      0   \n",
       "\n",
       "   Effusion  Emphysema  Fibrosis  Hernia  Infiltration  Mass  No Finding  \\\n",
       "0         0          0         0       0             0     0           0   \n",
       "1         0          1         0       0             0     0           0   \n",
       "2         1          0         0       0             0     0           0   \n",
       "3         0          0         0       0             0     0           1   \n",
       "4         0          0         0       1             0     0           0   \n",
       "\n",
       "   Nodule  Pleural_Thickening  Pneumonia  Pneumothorax  \n",
       "0       0                   0          0             0  \n",
       "1       0                   0          0             0  \n",
       "2       0                   0          0             0  \n",
       "3       0                   0          0             0  \n",
       "4       0                   0          0             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 69209 validated image filenames.\n",
      "Found 17302 validated image filenames.\n",
      "Found 25591 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "datagen=ImageDataGenerator(validation_split=0.2, rescale=1./255)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Set this to use the included split with the data set.\n",
    "train_df = pd.merge(train_filter,de_df , on='Image Index', how='inner')\n",
    "test_df = pd.merge(test_filter,de_df , on='Image Index', how='inner')\n",
    "\n",
    "batch_fit = 512\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "                dataframe=train_df,\n",
    "                directory=\"../images/\",\n",
    "                x_col=\"Image Index\",\n",
    "                y_col=all_labels,\n",
    "                batch_size=batch_fit,\n",
    "                seed=42,\n",
    "                shuffle=True,\n",
    "                class_mode= \"other\",\n",
    "                subset='training',\n",
    "                target_size=(128,128),\n",
    "                color_mode=\"grayscale\")\n",
    "\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "                dataframe=train_df,\n",
    "                directory=\"../images/\",\n",
    "                x_col=\"Image Index\",\n",
    "                y_col=all_labels,\n",
    "                batch_size=batch_fit,\n",
    "                seed=42,\n",
    "                shuffle=True,\n",
    "                class_mode= \"other\",\n",
    "                subset='validation',\n",
    "                target_size=(128,128),\n",
    "                color_mode=\"grayscale\")\n",
    "\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "                dataframe=test_df,\n",
    "                directory=\"../images/\",\n",
    "                x_col=\"Image Index\",\n",
    "                batch_size=all_labels,\n",
    "                seed=42,\n",
    "                shuffle=False,\n",
    "                class_mode=None,\n",
    "                target_size=(128,128),\n",
    "                color_mode=\"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\saber\\Anaconda3\\envs\\tfGPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\saber\\Anaconda3\\envs\\tfGPU\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(128,128,1))\n",
    "x = Conv2D(32, (3, 3), padding = 'same')(inp)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(32, (3, 3))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size = (2, 2))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Conv2D(64, (3, 3), padding = 'same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, (3, 3))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size = (2, 2))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "output1 = Dense(1, activation = 'sigmoid')(x)\n",
    "output2 = Dense(1, activation = 'sigmoid')(x)\n",
    "output3 = Dense(1, activation = 'sigmoid')(x)\n",
    "output4 = Dense(1, activation = 'sigmoid')(x)\n",
    "output5 = Dense(1, activation = 'sigmoid')(x)\n",
    "output6 = Dense(1, activation = 'sigmoid')(x)\n",
    "output7 = Dense(1, activation = 'sigmoid')(x)\n",
    "output8 = Dense(1, activation = 'sigmoid')(x)\n",
    "output9 = Dense(1, activation = 'sigmoid')(x)\n",
    "output10 = Dense(1, activation = 'sigmoid')(x)\n",
    "output11 = Dense(1, activation = 'sigmoid')(x)\n",
    "output12 = Dense(1, activation = 'sigmoid')(x)\n",
    "output13 = Dense(1, activation = 'sigmoid')(x)\n",
    "output14 = Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "model = Model(inp,[output1,\n",
    "                   output2,\n",
    "                   output3,\n",
    "                   output4,\n",
    "                   output5,\n",
    "                   output6,\n",
    "                   output7,\n",
    "                   output8,\n",
    "                   output9,\n",
    "                   output10,\n",
    "                   output11,\n",
    "                   output12,\n",
    "                   output13,\n",
    "                   output14\n",
    "                  ])\n",
    "\n",
    "model.compile(optimizers.rmsprop(lr = 0.001),\n",
    "loss = [\"binary_crossentropy\",\n",
    "        \"binary_crossentropy\",\n",
    "        \"binary_crossentropy\",\n",
    "        \"binary_crossentropy\",\n",
    "        \"binary_crossentropy\",\n",
    "        \"binary_crossentropy\",\n",
    "        \"binary_crossentropy\",\n",
    "        \"binary_crossentropy\",\n",
    "        \"binary_crossentropy\",\n",
    "        \"binary_crossentropy\",\n",
    "        \"binary_crossentropy\",\n",
    "        \"binary_crossentropy\",\n",
    "        \"binary_crossentropy\",\n",
    "        \"binary_crossentropy\"],metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_wrapper(generator):\n",
    "    for batch_x,batch_y in generator:\n",
    "        # 14 for the, 14 labels\n",
    "        yield (batch_x,[batch_y[:,i] for i in range(14)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\saber\\Anaconda3\\envs\\tfGPU\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/4\n",
      "  1/135 [..............................] - ETA: 28:30 - loss: 9.9333 - dense_2_loss: 0.7010 - dense_3_loss: 0.7167 - dense_4_loss: 0.6680 - dense_5_loss: 0.7615 - dense_6_loss: 0.7296 - dense_7_loss: 0.7664 - dense_8_loss: 0.6938 - dense_9_loss: 0.5833 - dense_10_loss: 0.7284 - dense_11_loss: 0.7445 - dense_12_loss: 0.6904 - dense_13_loss: 0.7709 - dense_14_loss: 0.6901 - dense_15_loss: 0.6887 - dense_2_acc: 0.4434 - dense_3_acc: 0.2910 - dense_4_acc: 0.7188 - dense_5_acc: 0.0879 - dense_6_acc: 0.2422 - dense_7_acc: 0.0410 - dense_8_acc: 0.4980 - dense_9_acc: 0.9941 - dense_10_acc: 0.2383 - dense_11_acc: 0.1250 - dense_12_acc: 0.5547 - dense_13_acc: 0.0488 - dense_14_acc: 0.5293 - dense_15_acc: 0.5547"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Your generator is NOT thread-safe.Keras requires a thread-safe generator when`use_multiprocessing=False, workers > 1`.For more information see issue #1638.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfGPU\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfGPU\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    656\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 657\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfGPU\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mworker\u001b[1;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfGPU\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[1;34m(uid)\u001b[0m\n\u001b[0;32m    625\u001b[0m     \"\"\"\n\u001b[1;32m--> 626\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: generator already executing",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-64f89570b646>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m                     \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                     verbose=1)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfGPU\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfGPU\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfGPU\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfGPU\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'generator already executing'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 raise RuntimeError(\n\u001b[1;32m--> 705\u001b[1;33m                     \u001b[1;34m\"Your generator is NOT thread-safe.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m                     \u001b[1;34m\"Keras requires a thread-safe generator when\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m                     \u001b[1;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Your generator is NOT thread-safe.Keras requires a thread-safe generator when`use_multiprocessing=False, workers > 1`.For more information see issue #1638."
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n // valid_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n // batch_fit\n",
    "\n",
    "\n",
    "model.fit_generator(generator=generator_wrapper(train_generator),\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=generator_wrapper(valid_generator),\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=4,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_generator(test_generator,\n",
    "                                workers = 24,\n",
    "                                steps=STEP_SIZE_TEST,\n",
    "                                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'Models3/MOSM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
