{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inporting our own functions\n",
    "from modules.TrainTestValGen import init_gens\n",
    "# @TODO add more to the modules folder to save space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @TODO clean up imports lol\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from time import sleep\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Activation, Dropout, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.backend.tensorflow_backend import clear_session\n",
    "from keras.backend.tensorflow_backend import get_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "BBox_df = pd.read_csv('../BBox_List_2017.csv')\n",
    "de_df = pd.read_csv('../Data_Entry_2017.csv')\n",
    "train_filter = pd.read_csv('../train_val_list.txt')\n",
    "train_filter.columns=['Image_Index']\n",
    "test_filter = pd.read_csv('../test_list.txt')\n",
    "test_filter.columns=['Image_Index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df =  86511  test_df =  25591\n"
     ]
    }
   ],
   "source": [
    "# clean up incorrect ages in the data\n",
    "bad_ages = de_df[de_df['Patient Age'] >= 100].index\n",
    "\n",
    "df = de_df.drop(bad_ages)\n",
    "\n",
    "df.drop(columns=['Unnamed: 11','OriginalImagePixelSpacing[x','y]','OriginalImage[Width','Height]'], inplace=True)\n",
    "\n",
    "df.columns = ['Image_Index', 'Finding_Labels', 'Follow-up', 'Patient ID',\n",
    "       'Patient_Age', 'Patient_Gender', 'View_Position']\n",
    "\n",
    "# Remove secondary labels\n",
    "# @TODO handle labels better\n",
    "df['Finding_Labels'] = df['Finding_Labels'].apply(lambda x: x.split('|')[0])\n",
    "\n",
    "\n",
    "# Join to the list of test and training to split the data set\n",
    "train_df = pd.merge(train_filter,df , on='Image_Index', how='inner')\n",
    "test_df = pd.merge(test_filter,df , on='Image_Index', how='inner')\n",
    "\n",
    "print(f'train_df =  {len(train_df)}  test_df =  {len(test_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Size Images \n",
    "# @TODO test to see what the pixle size is \n",
    "datagen = ImageDataGenerator(rescale=.07,validation_split=0.25)\n",
    "test_datagen=ImageDataGenerator(rescale=.07)\n",
    "\n",
    "# How we bin out the batches to run onto the GPU\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @TODO Get this working an import\n",
    "from _thread import start_new_thread\n",
    "\n",
    "#Attach CSV to Images Folder and defline our traiing validation and test\n",
    "def vaild_gen(batch_fit):\n",
    "    global valid_generator\n",
    "    valid_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=\"../images/\",\n",
    "        x_col=\"Image_Index\",\n",
    "        y_col=\"Finding_Labels\",\n",
    "        subset=\"validation\",\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=(15,15),\n",
    "        batch_size=batch_fit)\n",
    "    \n",
    "def train_gen(batch_fit):\n",
    "    global train_generator\n",
    "    train_generator=datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=\"../images/\",\n",
    "        x_col=\"Image_Index\",\n",
    "        y_col=\"Finding_Labels\",\n",
    "        subset=\"training\",\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=(15,15),\n",
    "        batch_size=batch_fit)\n",
    "    \n",
    "def test_gen(batch_fit):\n",
    "    global test_generator\n",
    "    test_generator=test_datagen.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        directory=\"../images/\",\n",
    "        x_col=\"Image_Index\",\n",
    "        y_col=\"Finding_Labels\",\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=(15,15),\n",
    "        batch_size=batch_fit)\n",
    "    \n",
    "def init_gens(batch_fit):\n",
    "    start_new_thread(vaild_gen,(batch_fit, ))\n",
    "    start_new_thread(train_gen,(batch_fit ,))\n",
    "    start_new_thread(test_gen,(batch_fit, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test 32 train 32 val 32 \n",
      "Found 23438 validated image filenames belonging to 15 classes.\n",
      "Found 19666 validated image filenames belonging to 15 classes.Found 59001 validated image filenames belonging to 15 classes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "init_gens(BATCH_SIZE)\n",
    "\n",
    "print(f' test {test_generator.batch_size} train {train_generator.batch_size} val {valid_generator.batch_size} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @TODO read https://medium.com/nanonets/how-to-easily-build-a-dog-breed-image-classification-model-2fd214419cde\n",
    "# and build a better CNN\n",
    "#layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(15, (3, 3), padding='same',\n",
    "                 input_shape=(15,15,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(15, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(15, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 86512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test Shape of data\n",
    "train_labels = to_categorical(train_df.shape)\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0728 13:32:30.687904  7448 deprecation_wrapper.py:119] From C:\\Users\\saber\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0728 13:32:30.692905  7448 deprecation_wrapper.py:119] From C:\\Users\\saber\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0728 13:32:30.742917  7448 deprecation.py:323] From C:\\Users\\saber\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1843/1843 [==============================] - 164s 89ms/step - loss: 1.6488 - acc: 0.5630 - val_loss: 1.6149 - val_acc: 0.6258\n",
      "Epoch 2/10\n",
      "1843/1843 [==============================] - 158s 86ms/step - loss: 1.5878 - acc: 0.5663 - val_loss: 1.6499 - val_acc: 0.6258\n",
      "Epoch 3/10\n",
      "1843/1843 [==============================] - 157s 85ms/step - loss: 1.5709 - acc: 0.5666 - val_loss: 1.5268 - val_acc: 0.6259\n",
      "Epoch 4/10\n",
      "1843/1843 [==============================] - 158s 85ms/step - loss: 1.5645 - acc: 0.5663 - val_loss: 1.5482 - val_acc: 0.6256\n",
      "Epoch 5/10\n",
      "1843/1843 [==============================] - 156s 85ms/step - loss: 1.5607 - acc: 0.5664 - val_loss: 1.5126 - val_acc: 0.6254\n",
      "Epoch 6/10\n",
      "1843/1843 [==============================] - 157s 85ms/step - loss: 1.5603 - acc: 0.5663 - val_loss: 1.4926 - val_acc: 0.6260\n",
      "Epoch 7/10\n",
      "1843/1843 [==============================] - 157s 85ms/step - loss: 1.5560 - acc: 0.5661 - val_loss: 1.4996 - val_acc: 0.6262\n",
      "Epoch 8/10\n",
      "1843/1843 [==============================] - 157s 85ms/step - loss: 1.5562 - acc: 0.5664 - val_loss: 1.5017 - val_acc: 0.6258\n",
      "Epoch 9/10\n",
      "1843/1843 [==============================] - 157s 85ms/step - loss: 1.5533 - acc: 0.5658 - val_loss: 1.5023 - val_acc: 0.6247\n",
      "Epoch 10/10\n",
      "1843/1843 [==============================] - 157s 85ms/step - loss: 1.5525 - acc: 0.5666 - val_loss: 1.4973 - val_acc: 0.6270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f74000cd68>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEP_SIZE_VALID= valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "STEP_SIZE_TRAIN= train_generator.n//train_generator.batch_size\n",
    "\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "\n",
    "\n",
    "model.compile(optimizers.rmsprop(lr=0.0001),\n",
    "loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    workers=16,\n",
    "                    use_multiprocessing=False,\n",
    "                    epochs=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting global Memory https://github.com/keras-team/keras/issues/12625\n",
    "# TODO move to module\n",
    "def reset_keras():\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    "\n",
    "    try:\n",
    "        del classifier # this is from global space - change this as you need\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(gc.collect()) # if it's done something you should see a number being outputted\n",
    "\n",
    "    # use the same config as you used to create the session\n",
    "    config = tensorflow.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "    config.gpu_options.visible_device_list = \"0\"\n",
    "    set_session(tensorflow.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_keras()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
